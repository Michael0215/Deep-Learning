{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import imutils\n",
    "import random\n",
    "import os, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "global img\n",
    "global point1, point2\n",
    "global g_rect\n",
    "global key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved：https://pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
    "def NMS(boxes, threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    boxes = np.array(boxes).astype(\"float\")\n",
    "\n",
    "    x_tl = boxes[:,0]  # Abscissa of top left corner vertex\n",
    "    y_tl = boxes[:,1]  # Ordinate of top left corner vertex\n",
    "    w = boxes[:,2]  # Width of bounding box\n",
    "    h = boxes[:,3]  # Height of bounding box\n",
    "    x_br = x_tl + w   \n",
    "    y_br = y_tl + h   \n",
    "    \n",
    "    area = (w + 1) * (h + 1)  # Calculate the area of each rectangular box, add 1 to make the IOU match without 0\n",
    "    temp = []\n",
    "    \n",
    "    idxs = np.argsort(h)  #Sort the elements in h from small to large and return the subscript of each element in h\n",
    "    \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        temp.append(i)   \n",
    "        \n",
    "        x_tl_m = np.maximum(x_tl[i], x_tl[idxs[:last]])   # Compare the abscissas of the upper left corner of other rectangles\n",
    "        y_tl_m = np.maximum(y_tl[i], y_tl[idxs[:last]])   # Pairwise comparison of the ordinates of the upper left corner of other rectangles\n",
    "\n",
    "        x_br_m = np.minimum(x_br[i], x_br[idxs[:last]]) \n",
    "        y_br_m = np.minimum(y_br[i], y_br[idxs[:last]])\n",
    "\n",
    "        w_m = np.maximum(0, x_br_m - x_tl_m + 1)  # Calculate the width of the bounding box\n",
    "        h_m = np.maximum(0, y_br_m - y_tl_m + 1)  # Calculate the height of the bounding box\n",
    "         \n",
    "        over = (w_m * h_m) / area[idxs[:last]]  # Calculates the ratio of the overlapping rectangle area to the area in area\n",
    "        \n",
    "        idxs = np.delete(idxs, np.concatenate(([last],   \n",
    "            np.where(over > threshold)[0])))    # remove overlapping rectangles\n",
    "\n",
    "    return boxes[temp].astype(\"int\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieved from: https://dandelioncloud.cn/article/details/1504109922504765442\n",
    "def on_mouse(event, x, y, flags, param):\n",
    "    global img, point1, point2, g_rect\n",
    "    img2 = img.copy()\n",
    "    count = 0\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:   \n",
    "        point1 = (x, y)\n",
    "        cv2.circle(img2, point1, 10, (0, 255, 0), 5)\n",
    "        cv2.imshow('pedestrians', img2)\n",
    "    elif event == cv2.EVENT_MOUSEMOVE and (flags & cv2.EVENT_FLAG_LBUTTON):   \n",
    "        cv2.rectangle(img2, point1, (x, y), (255, 0, 0), thickness=2)\n",
    "        cv2.imshow('pedestrians', img2)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:   \n",
    "        point2 = (x, y)\n",
    "        cv2.rectangle(img2, point1, point2, (0, 0, 255), thickness=2)\n",
    "        cv2.imshow('pedestrians', img2)\n",
    "        if point1 != point2:\n",
    "            min_x = min(point1[0], point2[0])\n",
    "            min_y = min(point1[1], point2[1])\n",
    "            width = abs(point1[0] - point2[0])\n",
    "            height = abs(point1[1] - point2[1])\n",
    "            g_rect = [min_x, min_y, width, height]\n",
    "            cut_img = img[min_y:min_y + height, min_x:min_x + width]\n",
    "            # Traverse the list that stores all the people in the current frame, obtain the coordinates of \n",
    "            # the center point of the corresponding person in the dictionary, and determine whether the \n",
    "            # coordinates of the center point are within the boundary of the cut image\n",
    "            for key in key_list:\n",
    "                if min_x<=dic_res[key][-1][0]<= min_x + width and min_y<=dic_res[key][-1][1]<= min_y + height: \n",
    "                    count += 1\n",
    "            cv2.putText(cut_img,   f'{count}'   ,(20,40), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,255,0),   2)\n",
    "            cv2.imshow('pedestrians_cut', cut_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_key(dic,value):\n",
    "    return [k for (k,v)in dic.items() if v == value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance(p1,p2):\n",
    "    x1,y1 = p1\n",
    "    x2,y2 = p2\n",
    "    return pow(pow(x1-x2,2)+pow(y1-y2,2),0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_color():\n",
    "    r = lambda: random.randint(0,255)\n",
    "    return (r(),r(),r())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def svmdetectpersons(img):\n",
    "    hog=cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    person, w = hog.detectMultiScale(img, winStride=(4, 4), padding=(8, 8),scale=1.05,useMeanshiftGrouping=False)\n",
    "#     person, w = hog.detectMultiScale(img,hitThreshold = -0.2)\n",
    "    return person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_center(image, person):\n",
    "    x, y, w, h = person\n",
    "    return (x+w//2, y+h//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_person(image, person,color):\n",
    "    x, y, w, h = person\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), color, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def absdiff_demo(img_1, img_2, sThre):\n",
    "    gray_image_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image_1 = cv2.GaussianBlur(gray_image_1,(5,5),0)    # GaussianBlur \n",
    "#     gray_image_1 = cv2.bilateralFilter(gray_image_1,-1,15,10)  \n",
    "    gray_image_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2GRAY)   \n",
    "    gray_image_2 = cv2.GaussianBlur(gray_image_2,(5,5),0)\n",
    "    d_frame = cv2.absdiff(gray_image_1,gray_image_2)         # Frame difference\n",
    "    ret, d_frame = cv2.threshold(d_frame, sThre, 255, cv2.THRESH_BINARY)  # Binarization\n",
    "    return d_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieved from: https://www.tutorialspoint.com/program-to-check-two-rectangular-overlaps-or-not-in-python\n",
    "# judge two people in group or not\n",
    "def booleanOverlap(nparray1, nparray2):\n",
    "    nparray3 = copy.deepcopy(nparray1)\n",
    "    nparray4 = copy.deepcopy(nparray2)\n",
    "    nparray3[2] = nparray3[0] + nparray3[2]\n",
    "    nparray3[3] = nparray3[1] + nparray3[3]\n",
    "    nparray4[2] = nparray4[0] + nparray4[2]\n",
    "    nparray4[3] = nparray4[1] + nparray4[3]\n",
    "    #Nparray3[0] the left abscissa of object one. Nparray4[2] right abscissa of object two\n",
    "    #Nparray3[2] the right abscissa of object one. Nparray4[0] left abscissa of object two\n",
    "    if (nparray3[0]>=nparray4[2]) or (nparray3[2]<=nparray4[0]) or (nparray3[3]<=nparray4[1]) or (nparray3[1]>=nparray4[3]):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# return number pedestrians in group working and walking alone\n",
    "def aloneOrGroup(filtered, frame_copy):\n",
    "    alone_count = 0\n",
    "    filtered_dict = {} #(coordinates:flag)\n",
    "    for i in range(len(filtered)):\n",
    "        flag = 0 #alone\n",
    "#         alone_count = 0\n",
    "        for j in range(len(filtered)):\n",
    "            if i==j: continue\n",
    "            else:\n",
    "                # Walking together means have intersection and have almost same size\n",
    "                # The width ratio is between 0.75 and 1.33, indicating that the two objects are about the same size. \n",
    "                # If they coincide, it means that they are groups together\n",
    "                if booleanOverlap(filtered[i], filtered[j]) == True and 0.75*filtered[j][3]<=filtered[i][3]<=1.33*filtered[j][3]:\n",
    "                    flag = 1 #group\n",
    "                    break\n",
    "        center_point = get_center(frame_copy,filtered[i])\n",
    "        filtered_dict[str(list(center_point))] = flag\n",
    "\n",
    "        if flag == 0:\n",
    "            alone_count += 1\n",
    "\n",
    "    # print(len(filtered))\n",
    "    # print(alone_count, len(filtered)-alone_count)\n",
    "    return alone_count, len(filtered)-alone_count, filtered_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_1 = cv2.imread('./train/STEP-ICCV21-02/000001.jpg')\n",
    "# img_2 = cv2.imread('./train/STEP-ICCV21-02/000002.jpg')\n",
    "# './test/STEP-ICCV21-01'\n",
    "# './test/STEP-ICCV21-07'\n",
    "# './train/STEP-ICCV21-02'\n",
    "# './train/STEP-ICCV21-09'\n",
    "# input the path here\n",
    "path = './test/STEP-ICCV21-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "loss_file_name = []\n",
    "files = os.listdir(path)  # Use listdir to read all files\n",
    "for i in files:\n",
    "    loss_file_name.append(path +'/' + i)\n",
    "    loss_file_name.sort(key=lambda x: x)  # Sort by numeric characters\n",
    "file_path = loss_file_name \n",
    "sThre = 40  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dic_res = {}\n",
    "key_people = []\n",
    "filtered_dict_prev = {}\n",
    "\n",
    "for img_path in file_path:\n",
    "    key_list = []\n",
    "    count_person_enter = 0\n",
    "    count_person_leave = 0\n",
    "    frame = cv2.imread(img_path)\n",
    "    if cv2.waitKey(1) & 0xFF == 13:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    frame_copy = frame.copy()\n",
    "    # Preliminary screening of pedestrians by three-frame difference method\n",
    "#     temp01 = absdiff_demo(img_1, img_2, sThre)\n",
    "#     temp12 = absdiff_demo(frame, img_2, sThre)\n",
    "#     img_1 = img_2\n",
    "#     img_2 = frame\n",
    "#     binary = cv2.bitwise_and(temp01,temp12)\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "#     erode = cv2.erode(binary,kernel,iterations=1) #erode\n",
    "#     dilate = cv2.dilate(erode,kernel,iterations=1) #dilate\n",
    "#     dilate = cv2.dilate(dilate,kernel,iterations=1) #dilate\n",
    "#     erode = cv2.erode(dilate,kernel,iterations=1) #erode\n",
    "    person = svmdetectpersons(frame)  \n",
    "    filtered = []\n",
    "    for item in NMS(person, threshold=0.8):\n",
    "        if get_center(frame_copy,item)[1]>400:\n",
    "            filtered.append(item)\n",
    "    t = aloneOrGroup(filtered, frame_copy)\n",
    "    if filtered_dict_prev == {}:\n",
    "        filtered_dict_prev = copy.deepcopy(t[2])\n",
    "\n",
    "    for p in filtered:    #  [[1,2,3,4],[2,3,4,5],[3,4,5,6],[6,7,8,9]]\n",
    "        flag_out = 0\n",
    "        # Get image center point\n",
    "        center_point = get_center(frame_copy,p)\n",
    "        # iterate the dictionary\n",
    "        for keys, values in dic_res.items():\n",
    "            # Calculate the distance between the new point and the point in the original dictionary\n",
    "            # values[-1] means only the closest comparison with all points\n",
    "            if calculate_distance(center_point,values[-1]) < 45:   ## \n",
    "                # If the distance is less than the threshold of 45, \n",
    "                # the two points are considered to be one target, \n",
    "                # and the center point is added to the corresponding position in the dictionary\n",
    "                if str(list(values[-1])) in filtered_dict_prev.keys() and str(list(center_point)) in t[2].keys():\n",
    "                    if filtered_dict_prev[str(list(values[-1]))] == 0 and t[2][str(list(center_point))] == 1:#group formation/yellow\n",
    "                        cv2.circle(frame_copy, center_point, 30, (0, 255, 255), 5)\n",
    "                    if filtered_dict_prev[str(list(values[-1]))] == 1 and t[2][str(list(center_point))] == 0:#group destruction/blue\n",
    "                        cv2.circle(frame_copy, center_point, 30, (255, 0, 0), 5)\n",
    "                filtered_dict_prev = copy.deepcopy(t[2])\n",
    "                new_list = values\n",
    "                new_list.append(center_point)\n",
    "                # new_list[-1][0] > frame_copy.shape[1] - 500 ：The center point is beyond the frame, and the distance from the right border of the frame to the right border of the image is 500\n",
    "                # new_list[-1][0] < 400 ：The center point is beyond the frame, and the distance from the left border of the frame to the left border of the image is 400\n",
    "                # new_list[-1][1] < 0 ：The center point is beyond the frame, and the distance from the upper border of the frame to the upper border of the image is 50\n",
    "                # new_list[-1][1] > frame_copy.shape[0] - 400 ：The center point is beyond the frame, and the distance from the lower border of the frame to the lower border of the image is 400\n",
    "                if new_list[-1][0] > frame_copy.shape[1] - 500 or new_list[-1][0] < 400 \\\n",
    "                    or new_list[-1][1] < 0 or new_list[-1][1] > frame_copy.shape[0] - 400:\n",
    "#                         cv2.circle(frame_copy, center_point, 10, (0, 255, 0), 5)\n",
    "#                         count_person_leave += 1\n",
    "                    if calculate_distance(new_list[-1],(frame_copy.shape[1]//2,frame_copy.shape[0]//2)) > \\\n",
    "                        calculate_distance(new_list[-2],(frame_copy.shape[1]//2,frame_copy.shape[0]//2)):\n",
    "                        cv2.circle(frame_copy, center_point, 10, (0, 255, 0), 5)\n",
    "                        count_person_leave += 1\n",
    "\n",
    "                if (new_list[-2][0] > frame_copy.shape[1] - 500 or new_list[-2][0] < 400 \\\n",
    "                    or new_list[-2][1] < 0  or new_list[-2][1] > frame_copy.shape[0] - 400) and \\\n",
    "                    (400 < center_point[0] < frame_copy.shape[1] - 500  \\\n",
    "                    and  0  < center_point[1] < frame_copy.shape[0] - 400):\n",
    "                    cv2.circle(frame_copy, center_point, 30, (0, 0, 255), 5)\n",
    "                    count_person_enter += 1\n",
    "                # Rewrite the values of the corresponding keys\n",
    "                dic_res[keys] = new_list       #   dic_res[A] = [[1,2],[2,3]]   # [2,3]\n",
    "                draw_person(frame_copy,p,keys)\n",
    "                key_list.append(keys)\n",
    "                for i in range(len(new_list)-1):\n",
    "                    cv2.line(frame_copy, new_list[i], new_list[i+1], keys, thickness=2)\n",
    "                flag_out = 1\n",
    "                break\n",
    "        # If the old center point is not found within the threshold distance from the new center point after traversing the dictionary, \n",
    "        # the new center point is considered to be the center point of the new character, and a new person is added in dic_res\n",
    "        if flag_out != 1:\n",
    "            dic_res[get_random_color()] = [center_point]\n",
    "            keys = get_key(dic_res,[center_point])[0]\n",
    "            draw_person(frame_copy,p,keys)\n",
    "            key_list.append(keys)\n",
    "            if center_point[0] < frame_copy.shape[1] - 400 or center_point[0] > 400 \\\n",
    "            or center_point[1] > 0  or center_point[1] < frame_copy.shape[0] - 400:\n",
    "                cv2.circle(frame_copy, center_point, 30, (0, 0, 255), 5)\n",
    "                count_person_enter += 1\n",
    "    key_people = key_list\n",
    "    cv2.putText(frame_copy,   f'People number:{len(filtered)}'   ,(0,40), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,255,0),   2)\n",
    "    cv2.putText(frame_copy, f'Number of People walking alone:{t[0]}',(0,80), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,0,255),   2)\n",
    "    cv2.putText(frame_copy, f'Number of People walking in group:{t[1]}',(0,120), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,0,255),   2)\n",
    "    cv2.putText(frame_copy, f'Number of People enter the scene:{count_person_enter}',(0,160), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,0,255),   2)\n",
    "    cv2.putText(frame_copy, f'Number of People leave the scene:{count_person_leave}',(0,200), cv2.FONT_HERSHEY_COMPLEX,   1,  (0,255,0),   2)\n",
    "    img = frame_copy\n",
    "    cv2.namedWindow('pedestrians')\n",
    "    cv2.startWindowThread()\n",
    "    cv2.imshow('pedestrians', frame_copy)\n",
    "    cv2.setMouseCallback('pedestrians', on_mouse)\n",
    "\n",
    "    # Press \"Enter\" to exit the window\n",
    "    if cv2.waitKey(1) & 0xFF == 13:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
